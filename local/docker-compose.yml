version: "3.8"

services:
  # --- Infrastructure ---
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: visawire
      POSTGRES_USER: visawire
      POSTGRES_PASSWORD: visawire_local
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./services/visa_db/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      - ./services/visa_db/seed/destinations.sql:/docker-entrypoint-initdb.d/02-destinations.sql
      - ./services/visa_db/seed/questions.sql:/docker-entrypoint-initdb.d/03-questions.sql
      - ./services/visa_db/seed/followups.sql:/docker-entrypoint-initdb.d/04-followups.sql
      - ./services/visa_db/seed/risk_factors.sql:/docker-entrypoint-initdb.d/05-risk_factors.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U visawire"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  # --- Application ---
  orchestrator:
    build:
      context: .
      dockerfile: infra/docker/orchestrator.Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - POSTGRES_HOST=postgres
      - LLM_API_URL=http://llm:11434
      - VISA_DB_PATH=/app/services/visa_db/visa.db
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./web:/app/web

  # --- ML Services (require GPU) ---
  llm:
    build:
      context: .
      dockerfile: infra/docker/llm.Dockerfile
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ollama_data:/root/.ollama

  asr:
    build:
      context: .
      dockerfile: infra/docker/asr.Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - model_cache:/root/.cache

  tts:
    build:
      context: .
      dockerfile: infra/docker/tts.Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - model_cache:/root/.cache

volumes:
  pgdata:
  ollama_data:
  model_cache:
